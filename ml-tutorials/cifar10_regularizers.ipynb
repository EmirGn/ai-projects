{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l6OHToQ7Bah9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "id": "e7hB0XYSFI1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171496d2-5346-4970-f479-e34ed851c83c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(32, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
        "        inputs\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
        "        x\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(\n",
        "        128, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01),)(\n",
        "        x\n",
        "    )\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "2pMbzsonFOR6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = my_model()\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFaQZIJ2FeOz",
        "outputId": "ec6d9b9b-f4ee-44b5-d8ba-6684f728c0c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=64, epochs=150, verbose=1)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "id": "5R3Vo1-gGN7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrWuWUoNJwt1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}