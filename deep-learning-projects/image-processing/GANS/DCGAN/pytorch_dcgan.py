# -*- coding: utf-8 -*-
"""pytorch_dcgan.ipynb

Automatically generated by Colaboratory.

Original file is located at it is free to use and modify
    https://colab.research.google.com/drive/1KH-IyNmFRs4i-G71_EA5YIZ3Ta_nM7hQ
"""

from __future__ import print_function
import argparse
import os
import random
import torchvision
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
from torch.utils.data import DataLoader, Dataset
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
from PIL import Image

manualSeed = 999
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

#Take dataset from kaggle with api
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d alessiocorrado99/animals10
!unzip animals10

#Delete unnecesseray folders
!rm -r /content/raw-img/farfalla
!rm -r /content/raw-img/scoiattolo
!rm -r /content/raw-img/ragno

#Hyperparameters
dataroot = "/content/raw_data"
workers = 2
batch_size = 128
image_size = 64
nc = 3
nz = 100
ngf = 64
ndf = 64
num_epochs = 5
lr = 0.0002
beta1 = 0.5
ngpu = 1

#Transform Compose
transform_compose = transforms.Compose([
    transforms.Resize(image_size),
    transforms.CenterCrop(image_size),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

#Custom dataset
class CustomDataset(Dataset):
    def __init__(self, root_dir, transform):
        self.root_dir = root_dir
        self.classes = os.listdir(root_dir)
        self.img_paths = []
        for c in self.classes:
            class_path = os.path.join(root_dir, c)
            img_files = os.listdir(class_path)
            self.img_paths += [(os.path.join(class_path, img), self.classes.index(c)) for img in img_files]
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path, class_idx = self.img_paths[idx]
        img = Image.open(img_path)
        if self.transform:
            img = self.transform(img)
        return img, class_idx

#Change the subdirectory's name

translate = {"cane": "dog", "cavallo": "horse", "elefante": "elephant", "gallina": "chicken", "gatto": "cat", "mucca": "cow", "pecora": "sheep"}

import os

for eski_isim, yeni_isim in translate.items():
    eski_yol = os.path.join("raw-img", eski_isim)
    yeni_yol = os.path.join("raw-img", yeni_isim)
    os.rename(eski_yol, yeni_yol)

dataset = datasets.MNIST(
    root = "data",
    download = True,
    transform = transform_compose
)

dataloader = DataLoader(dataset, batch_size, shuffle = True, num_workers = workers)

device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# Plot some training images
real_batch = next(iter(dataloader))
plt.figure(figsize=(16, 16))
plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),

            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),

            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),

            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, input):
        return self.main(input)

gen = Generator(ngpu).to(device)

if (device.type == 'cuda') and (ngpu > 1):
    gen = nn.DataParallel(gen, list(range(ngpu)))

gen.apply(weights_init)

print(gen)

class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

disc = Discriminator(ngpu).to(device)

if (device.type == 'cuda') and (ngpu > 1):
    disc = nn.DataParallel(disc, list(range(ngpu)))

disc.apply(weights_init)

print(disc)

loss = nn.BCELoss()
fixed_noise = torch.randn(64, nz, 1, 1, device=device)

real_label = 1
fake_label = 0

optimizerD = optim.Adam(disc.parameters(), lr = lr, betas = (beta1, 0.999))
optimizerG = optim.Adam(gen.parameters(), lr = lr, betas = (beta1, 0.999))

img_list = []
G_loss = []
D_loss = []
iters = 0

print("Starting training...")

for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):

        # Update discriminator network
        disc.zero_grad()
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        label = torch.full((b_size,), real_label, dtype = torch.float, device = device)

        output = disc(real_cpu).view(-1)
        err_disc_real = loss(output, label)

        err_disc_real.backward()
        d_x = output.mean().item()

        noise = torch.randn(b_size, nz, 1, 1, device=device)
        fake = gen(noise)
        label.fill_(fake_label)

        output = disc(fake.detach()).view(-1)
        err_disc_fake = loss(output, label)
        err_disc_fake.backward()
        d_g_z1 = output.mean().item()

        err_disc = err_disc_real + err_disc_fake
        optimizerD.step()

        #Update generator network
        gen.zero_grad()
        label.fill_(real_label)

        output = disc(fake).view(-1)
        err_gen = loss(output, label)
        err_gen.backward()
        d_g_z2 = output.mean().item()

        optimizerG.step()

        #Stats for training

        if i % 50 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs, i, len(dataloader),
                     err_disc.item(), err_gen.item(), d_x, d_g_z1, d_g_z2))
            
        G_loss.append(err_gen.item())
        D_loss.append(err_disc.item())

        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake = gen(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake, padding = 2, normalize = True))

        iters += 1

plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_loss,label="G")
plt.plot(D_loss,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

real_batch = next(iter(dataloader))

# Plot the real images
plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))

# Plot the fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.show()

